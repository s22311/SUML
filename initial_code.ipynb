{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3055010,"sourceType":"datasetVersion","datasetId":1548204}],"dockerImageVersionId":30458,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Giving the data set full_data_flightdelay.csv in the archive,\n# the task is to predict the delay of a flight in minutes.\n# The data set contains the following columns:\n# MONTH:\t\t\t\tMonth\n# DAY_OF_WEEK:\t\t\tDay of Week\n# DEP_DEL15: \t\t\tTARGET Binary of a departure delay over 15 minutes (1 is yes)\n# DEP_TIME_BLK:\t\t\tDeparture time block\n# DISTANCE_GROUP:\t\t\tDistance group to be flown by departing aircraft\n# SEGMENT_NUMBER:\t\t\tThe segment that this tail number is on for the day\n# CONCURRENT_FLIGHTS:\t\tConcurrent flights leaving from the airport in the same departure block\n# NUMBER_OF_SEATS:\t\tNumber of seats on the aircraft\n# CARRIER_NAME:\t\t\tCarrier\n# AIRPORT_FLIGHTS_MONTH:\t\tAvg Airport Flights per Month\n# AIRLINE_FLIGHTS_MONTH:\t\tAvg Airline Flights per Month\n# AIRLINE_AIRPORT_FLIGHTS_MONTH:\tAvg Flights per month for Airline AND Airport\n# AVG_MONTHLY_PASS_AIRPORT:\tAvg Passengers for the departing airport for the month\n# AVG_MONTHLY_PASS_AIRLINE:\tAvg Passengers for airline for month\n# FLT_ATTENDANTS_PER_PASS:\tFlight attendants per passenger for airline\n# GROUND_SERV_PER_PASS:\t\tGround service employees (service desk) per passenger for airline\n# PLANE_AGE:\t\t\tAge of departing aircraft\n# DEPARTING_AIRPORT:\t\tDeparting Airport\n# LATITUDE:\t\t\tLatitude of departing airport\n# LONGITUDE:\t\t\tLongitude of departing airport\n# PREVIOUS_AIRPORT:\t\tPrevious airport that aircraft departed from\n# PRCP:\t\t\t\tInches of precipitation for day\n# SNOW:\t\t\t\tInches of snowfall for day\n# SNWD:\t\t\t\tInches of snow on ground for day\n# TMAX:\t\t\t\tMax temperature for day\n# AWND:\t\t\t\tMax wind speed for day\n\n\n\n# Build a classification model using various supervised machine and unsupervised machine learning models\n# learning models and check which model gives you the best accuracy\n\n# use the following models for supervised machine learning\n# 1. Logistic Regression\n# 2. Decision Tree\n# 3. GaussianNB\n# 4. MLPClassifier\n\n# using some deep learning models\n# 1. Long Short-Term Memory (LSTM)\n\n\n# using hyperparameter tuning to improve the accuracy of the models\n","metadata":{"execution":{"iopub.execute_input":"2023-04-23T20:22:20.532536Z","iopub.status.busy":"2023-04-23T20:22:20.53215Z","iopub.status.idle":"2023-04-23T20:22:20.538974Z","shell.execute_reply":"2023-04-23T20:22:20.537717Z"},"papermill":{"duration":0.024064,"end_time":"2023-04-23T20:22:20.541639","exception":false,"start_time":"2023-04-23T20:22:20.517575","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Importing the libraries\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\n# Define the path to the data set\n# '../input/2019-airline-delays-and-cancellations/full_data_flightdelay.csv'\npath = '../input/2019-airline-delays-and-cancellations/full_data_flightdelay.csv'","metadata":{"execution":{"iopub.execute_input":"2023-04-23T20:22:20.567064Z","iopub.status.busy":"2023-04-23T20:22:20.565905Z","iopub.status.idle":"2023-04-23T20:22:20.575472Z","shell.execute_reply":"2023-04-23T20:22:20.57461Z"},"id":"y9yKcH48B1IP","papermill":{"duration":0.024572,"end_time":"2023-04-23T20:22:20.577694","exception":false,"start_time":"2023-04-23T20:22:20.553122","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# importing the dataset\ndf = pd.read_csv(path)\n\n# checking the dataset\ndf.head()","metadata":{"execution":{"iopub.execute_input":"2023-04-23T20:22:20.602124Z","iopub.status.busy":"2023-04-23T20:22:20.601724Z","iopub.status.idle":"2023-04-23T20:22:58.146868Z","shell.execute_reply":"2023-04-23T20:22:58.145618Z"},"id":"uwnV-o2RBz3h","outputId":"f5725d9a-17e4-451f-d7eb-cf0d20983a12","papermill":{"duration":37.574026,"end_time":"2023-04-23T20:22:58.163016","exception":false,"start_time":"2023-04-23T20:22:20.58899","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# show the shape of the dataset and the number of rows and columns\ndf.shape","metadata":{"execution":{"iopub.execute_input":"2023-04-23T20:22:58.188027Z","iopub.status.busy":"2023-04-23T20:22:58.187581Z","iopub.status.idle":"2023-04-23T20:22:58.193702Z","shell.execute_reply":"2023-04-23T20:22:58.192856Z"},"id":"5tbqAVyYCobJ","outputId":"f9db6b84-10cd-45ce-9830-ab22e39e4331","papermill":{"duration":0.021344,"end_time":"2023-04-23T20:22:58.195916","exception":false,"start_time":"2023-04-23T20:22:58.174572","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check the data types of the columns\ndf.info()","metadata":{"execution":{"iopub.execute_input":"2023-04-23T20:22:58.222109Z","iopub.status.busy":"2023-04-23T20:22:58.221315Z","iopub.status.idle":"2023-04-23T20:22:58.244128Z","shell.execute_reply":"2023-04-23T20:22:58.242833Z"},"id":"t4GTC7tFCypN","outputId":"b39b0fa5-2ece-4a9b-8fea-ccee3c476290","papermill":{"duration":0.038744,"end_time":"2023-04-23T20:22:58.246541","exception":false,"start_time":"2023-04-23T20:22:58.207797","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# encode the categorical data\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\n\ndef clean_labels_encoder(list_of_labels, df):\n    for label in list_of_labels:\n        df[label] = le.fit_transform(df[label])\n    return df\n\n# clean the labels\nlist_of_labels = ['CARRIER_NAME', 'DEPARTING_AIRPORT', 'PREVIOUS_AIRPORT', 'DEP_TIME_BLK']\ndf = clean_labels_encoder(list_of_labels, df)\n\n# show head of the dataset\ndf.head()","metadata":{"execution":{"iopub.execute_input":"2023-04-23T20:22:58.272477Z","iopub.status.busy":"2023-04-23T20:22:58.271819Z","iopub.status.idle":"2023-04-23T20:23:06.01713Z","shell.execute_reply":"2023-04-23T20:23:06.015916Z"},"id":"G0D4XBZBC1_E","outputId":"f34b37c5-c4b0-4acc-8f24-e2659f5b7744","papermill":{"duration":7.761402,"end_time":"2023-04-23T20:23:06.01992","exception":false,"start_time":"2023-04-23T20:22:58.258518","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check the data types of the columns\ndf.info()","metadata":{"execution":{"iopub.execute_input":"2023-04-23T20:23:06.046883Z","iopub.status.busy":"2023-04-23T20:23:06.046001Z","iopub.status.idle":"2023-04-23T20:23:06.059395Z","shell.execute_reply":"2023-04-23T20:23:06.057578Z"},"id":"Va7qThv8C4Tb","outputId":"646046eb-0ee1-4c81-d698-423e7dd93e72","papermill":{"duration":0.029623,"end_time":"2023-04-23T20:23:06.061929","exception":false,"start_time":"2023-04-23T20:23:06.032306","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# describe the dataset\ndf.describe()","metadata":{"execution":{"iopub.execute_input":"2023-04-23T20:23:06.08912Z","iopub.status.busy":"2023-04-23T20:23:06.088704Z","iopub.status.idle":"2023-04-23T20:23:11.599324Z","shell.execute_reply":"2023-04-23T20:23:11.597987Z"},"id":"8l1ZBDSyC5pH","outputId":"7aba2566-5c58-462c-ccdf-211335f25d37","papermill":{"duration":5.527428,"end_time":"2023-04-23T20:23:11.601947","exception":false,"start_time":"2023-04-23T20:23:06.074519","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fill the missing values with mean\ndf.fillna(df.mean(), inplace=True)\n\n# show correlation\ndf.corr()","metadata":{"execution":{"iopub.execute_input":"2023-04-23T20:23:12.048651Z","iopub.status.busy":"2023-04-23T20:23:12.048255Z","iopub.status.idle":"2023-04-23T20:23:24.84227Z","shell.execute_reply":"2023-04-23T20:23:24.840734Z"},"id":"f6T7kZmJDBwI","outputId":"83922120-a7f5-4103-af99-6ef60b5af403","papermill":{"duration":12.810967,"end_time":"2023-04-23T20:23:24.844628","exception":false,"start_time":"2023-04-23T20:23:12.033661","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# show correlation in a heatmap\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# show the correlation in a plt figure\ndef show_correlation(df):\n    plt.figure(figsize=(20, 10))\n    sns.set(style='whitegrid', context='notebook')\n    cols = [0, 1, 2]\n    sns.heatmap(df.corr(), annot=True, square=False, cmap='coolwarm')\n    plt.show()\n\n# show the correlation\nshow_correlation(df)\n","metadata":{"execution":{"iopub.execute_input":"2023-04-23T20:23:24.875638Z","iopub.status.busy":"2023-04-23T20:23:24.874487Z","iopub.status.idle":"2023-04-23T20:23:41.42883Z","shell.execute_reply":"2023-04-23T20:23:41.427534Z"},"id":"cEfNXiyWDEL1","outputId":"838c21e3-8194-4736-e7bd-5751a9feeb78","papermill":{"duration":16.582265,"end_time":"2023-04-23T20:23:41.440892","exception":false,"start_time":"2023-04-23T20:23:24.858627","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# split the data into features and target\n# target is DEP_DEL15\n\nX = df.iloc[:, [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22]].values\ny = df.iloc[:, 2].values\n\nX","metadata":{"execution":{"iopub.execute_input":"2023-04-23T20:23:41.49515Z","iopub.status.busy":"2023-04-23T20:23:41.494655Z","iopub.status.idle":"2023-04-23T20:23:42.29833Z","shell.execute_reply":"2023-04-23T20:23:42.297185Z"},"id":"Z6LeV1qbDbL7","outputId":"7dedc460-f99f-4836-90f9-1af087563582","papermill":{"duration":0.834038,"end_time":"2023-04-23T20:23:42.301136","exception":false,"start_time":"2023-04-23T20:23:41.467098","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# covert the data into 0 - 1 range using minmax scaler\n\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef scale_data(X):\n    scaler = MinMaxScaler()\n    X_scaler = scaler.fit_transform(X)\n    return X_scaler\n\nX_scaler = scale_data(X)\ndf = pd.DataFrame(X_scaler)\n\ndf.head()","metadata":{"execution":{"iopub.execute_input":"2023-04-23T20:23:42.355636Z","iopub.status.busy":"2023-04-23T20:23:42.354697Z","iopub.status.idle":"2023-04-23T20:23:43.657914Z","shell.execute_reply":"2023-04-23T20:23:43.656842Z"},"id":"hhU7olpaDwiO","outputId":"269a8f72-9f07-4344-a540-e8160b3f47d7","papermill":{"duration":1.33384,"end_time":"2023-04-23T20:23:43.660953","exception":false,"start_time":"2023-04-23T20:23:42.327113","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# split the data into training and testing sets\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X_scaler, y, test_size=0.3, random_state=42)\n\nX_train.shape","metadata":{"execution":{"iopub.execute_input":"2023-04-23T20:23:43.715198Z","iopub.status.busy":"2023-04-23T20:23:43.714235Z","iopub.status.idle":"2023-04-23T20:23:46.163351Z","shell.execute_reply":"2023-04-23T20:23:46.162419Z"},"id":"TZIxxDY7DzJk","outputId":"3b3bdbe1-1c4f-4941-954e-088578034f76","papermill":{"duration":2.479297,"end_time":"2023-04-23T20:23:46.165873","exception":false,"start_time":"2023-04-23T20:23:43.686576","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Build a classification model using various supervised machine \n# learning models and check which model gives you the best accuracy\n\n# use the following models\n# 1. Logistic Regression\n# 2. Decision Tree\n# 3. GaussianNB\n# 4. MLPClassifier","metadata":{"execution":{"iopub.execute_input":"2023-04-23T20:23:46.22041Z","iopub.status.busy":"2023-04-23T20:23:46.219572Z","iopub.status.idle":"2023-04-23T20:23:46.224575Z","shell.execute_reply":"2023-04-23T20:23:46.223823Z"},"id":"4YpuQQjwD10_","papermill":{"duration":0.035059,"end_time":"2023-04-23T20:23:46.226979","exception":false,"start_time":"2023-04-23T20:23:46.19192","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create a function to train the models\n# check the accuracy of the model\nfrom sklearn.metrics import confusion_matrix, classification_report\n\ndef separator(count = 50):\n    print('-'*count)\n\ndef train_model_and_print_accuracy(model, X_train, y_train, X_test, y_test):\n    model.fit(X_train, y_train)\n\n    # score train and test sets\n    scoreTest = model.score(X_train, y_train)\n    scoreTrain = model.score(X_test, y_test)\n\n    # predict the test data\n    predict_test = model.predict(X_test)\n\n    cm_result = confusion_matrix(y_test, predict_test)\n    cr_result = classification_report(y_test,predict_test)\n\n    model_name = str(model).split('(')[0]\n\n    # print model name in blue color\n    print('\\033[1m' + model_name + '\\033[0m')\n    # print -----------------------------------\n    separator()\n    print('Train Score for '+str(model_name)+': ', (scoreTest))\n    separator()\n    print('Test Score for '+str(model_name)+': ', (scoreTrain))\n    separator()\n    print('Confusion Matrix for '+str(model_name)+' for test : \\n', (cm_result))\n    separator()\n    print('Classification Report for '+str(model_name)+' for test : \\n', str(cr_result))\n    separator()\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# using logistic regression\n# 1. Logistic Regression\n# 2. Decision Tree\n# 3. GaussianNB\n# 4. MLPClassifier\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neural_network import MLPClassifier\n\nlog_reg = LogisticRegression()\ndt = DecisionTreeClassifier(max_depth=3)\ngnb = GaussianNB()\nmlp = MLPClassifier(random_state=1, max_iter=300)\n\n# train the models and print the accuracy\nmodels = [log_reg, dt, gnb, mlp]\n\nfor model in models:\n    train_model_and_print_accuracy(model, X_train, y_train, X_test, y_test)","metadata":{"execution":{"iopub.execute_input":"2023-04-23T20:23:46.280971Z","iopub.status.busy":"2023-04-23T20:23:46.280545Z","iopub.status.idle":"2023-04-23T20:24:44.892266Z","shell.execute_reply":"2023-04-23T20:24:44.891161Z"},"id":"3Tup1sQDD34Y","outputId":"dbad9815-ec57-4b5e-c455-183ffdbb852a","papermill":{"duration":58.642023,"end_time":"2023-04-23T20:24:44.895061","exception":false,"start_time":"2023-04-23T20:23:46.253038","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# conclusion before PCA - principal component analysis\n\n# show that best modal is MLPClassifier with 0.816 accuracy (approx)","metadata":{"execution":{"iopub.execute_input":"2023-04-23T21:13:12.729711Z","iopub.status.busy":"2023-04-23T21:13:12.728582Z","iopub.status.idle":"2023-04-23T21:13:12.734112Z","shell.execute_reply":"2023-04-23T21:13:12.733181Z"},"id":"JIrmyXWtbPin","papermill":{"duration":0.037791,"end_time":"2023-04-23T21:13:12.736428","exception":false,"start_time":"2023-04-23T21:13:12.698637","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Now use PCA to reduce the dimensionality of the data and\n# retrain the models to see what impacts it has on your model in terms of accuracy.\n# keep in mind that many times doing PCA can actually decrease the accuracy of your model\n# but computation is much lighter and that's trade off you need to consider while build models in real life","metadata":{"execution":{"iopub.execute_input":"2023-04-23T21:13:12.794283Z","iopub.status.busy":"2023-04-23T21:13:12.793471Z","iopub.status.idle":"2023-04-23T21:13:12.798818Z","shell.execute_reply":"2023-04-23T21:13:12.797723Z"},"id":"439p_4cjbNks","papermill":{"duration":0.036823,"end_time":"2023-04-23T21:13:12.801131","exception":false,"start_time":"2023-04-23T21:13:12.764308","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# use PCA to reduce the dimensionality of the data\n\nfrom sklearn.decomposition import PCA\n\npca = PCA(0.95)\n\nx_pca = pca.fit_transform(X_scaler)\n\n# Show the number of components\nx_pca.shape","metadata":{"execution":{"iopub.execute_input":"2023-04-23T21:13:12.860803Z","iopub.status.busy":"2023-04-23T21:13:12.860074Z","iopub.status.idle":"2023-04-23T21:13:21.761567Z","shell.execute_reply":"2023-04-23T21:13:21.760427Z"},"id":"2G8jgVwFbTnX","outputId":"bd5eb48c-da4c-41b3-ea13-2ff9603e22f3","papermill":{"duration":8.934064,"end_time":"2023-04-23T21:13:21.764119","exception":false,"start_time":"2023-04-23T21:13:12.830055","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# split the data into training and testing sets using the new data\n\nX_train, X_test, y_train, y_test = train_test_split(x_pca, y, test_size=0.3, random_state=42)","metadata":{"execution":{"iopub.execute_input":"2023-04-23T21:13:21.822394Z","iopub.status.busy":"2023-04-23T21:13:21.821623Z","iopub.status.idle":"2023-04-23T21:13:23.590767Z","shell.execute_reply":"2023-04-23T21:13:23.589573Z"},"id":"NKPvvJ8iba-D","papermill":{"duration":1.801435,"end_time":"2023-04-23T21:13:23.59353","exception":false,"start_time":"2023-04-23T21:13:21.792095","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# now retrain the models\nprint('*'*25, 'PCA', '*'*25)\nfor model in models:\n    train_model_and_print_accuracy(model, X_train, y_train, X_test, y_test)","metadata":{"execution":{"iopub.execute_input":"2023-04-23T21:13:23.715661Z","iopub.status.busy":"2023-04-23T21:13:23.715261Z","iopub.status.idle":"2023-04-23T21:13:32.409659Z","shell.execute_reply":"2023-04-23T21:13:32.407709Z"},"id":"jKGb-eTnbfLg","outputId":"57fccc18-4cd6-4bdc-9fa9-74578db4dace","papermill":{"duration":8.726522,"end_time":"2023-04-23T21:13:32.412378","exception":false,"start_time":"2023-04-23T21:13:23.685856","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# conclusion before PCA - principal component analysis\n\n# show that best modal is MLPClassifier with 0.811 accuracy (approx)","metadata":{"execution":{"iopub.execute_input":"2023-04-23T21:41:59.140253Z","iopub.status.busy":"2023-04-23T21:41:59.139871Z","iopub.status.idle":"2023-04-23T21:41:59.144565Z","shell.execute_reply":"2023-04-23T21:41:59.143367Z"},"id":"fIMJ-pRPGTj8","papermill":{"duration":0.039956,"end_time":"2023-04-23T21:41:59.146927","exception":false,"start_time":"2023-04-23T21:41:59.106971","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# conclusion before PCA - principal component analysis\n# However, it's important to note that accuracy alone is not always the best metric \n# for evaluating the performance of AI models. Depending on the task at hand, \n# other metrics such as precision, recall, F1-score, or AUC-ROC might be more appropriate.\n\n# there LogisticRegression, DecisionTreeClassifier and GaussianNB are the best to use after PCA","metadata":{"execution":{"iopub.execute_input":"2023-04-23T21:41:59.210921Z","iopub.status.busy":"2023-04-23T21:41:59.210481Z","iopub.status.idle":"2023-04-23T21:41:59.214657Z","shell.execute_reply":"2023-04-23T21:41:59.213843Z"},"papermill":{"duration":0.038994,"end_time":"2023-04-23T21:41:59.216718","exception":false,"start_time":"2023-04-23T21:41:59.177724","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# importing the dataset\ndf = pd.read_csv(path)\n\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\n\n# encode the categorical data\n# clean the labels\nlist_of_labels = ['CARRIER_NAME', 'DEPARTING_AIRPORT', 'PREVIOUS_AIRPORT', 'DEP_TIME_BLK']\ndf = clean_labels_encoder(list_of_labels, df)\n\n# split the data into features and target\n# target is DEP_DEL15\n\nX = df.iloc[:, [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22]].values\ny = df.iloc[:, 2].values\n\n# covert the data into 0 - 1 range using minmax scaler\n\nX_scaler = scale_data(X)\ndf = pd.DataFrame(X_scaler)\n\n# split the data into training and testing sets\n\n# split the data into training and testing sets\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X_scaler, y, test_size=0.3, random_state=42)\n\nX_train.shape\n\n# checking the dataset\ndf.head()","metadata":{"execution":{"iopub.execute_input":"2023-04-23T21:41:59.28142Z","iopub.status.busy":"2023-04-23T21:41:59.280636Z","iopub.status.idle":"2023-04-23T21:42:41.823316Z","shell.execute_reply":"2023-04-23T21:42:41.822092Z"},"papermill":{"duration":42.608801,"end_time":"2023-04-23T21:42:41.856818","exception":false,"start_time":"2023-04-23T21:41:59.248017","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# using some deep learning models\n\n# 1. using Long Short-Term Memory - using keras\n\nimport pandas as pd\nimport numpy as np\nfrom keras.models import Sequential\nfrom keras.layers import LSTM, Dense, Dropout\n\n\npath = '../input/2019-airline-delays-and-cancellations/full_data_flightdelay.csv'\n# Load the dataset and preprocess the data\ndf = pd.read_csv(path)\n\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\n\n# encode the categorical data\n# clean the labels\nlist_of_labels = ['CARRIER_NAME', 'DEPARTING_AIRPORT', 'PREVIOUS_AIRPORT', 'DEP_TIME_BLK']\ndf = clean_labels_encoder(list_of_labels, df)\n\n# Define the input and target variables\nX = df.drop(columns=['DEP_DEL15'])\ny = df['DEP_DEL15']\n\n# Split the data into training and testing sets\ntrain_size = int(len(X) * 0.7)\nX_train, X_test = X[:train_size], X[train_size:]\ny_train, y_test = y[:train_size], y[train_size:]\n\n# Scale the data using a MinMaxScaler\nscaler = MinMaxScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\n# Reshape the data for input to the LSTM model\nX_train = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\nX_test = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))\n\n# Define the model architecture\nmodel = Sequential()\nmodel.add(LSTM(64, input_shape=(1, X_train.shape[2]), return_sequences=True))\nmodel.add(Dropout(0.2))\nmodel.add(LSTM(32, return_sequences=True))\nmodel.add(Dropout(0.2))\nmodel.add(LSTM(16))\nmodel.add(Dense(1, activation='sigmoid'))\n\n# Compile the model\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n\n# Train the model\nhistory = model.fit(X_train, y_train, epochs=5, batch_size=64, validation_data=(X_test, y_test), verbose=2, shuffle=False)\n\n# Evaluate the model on the test set\nscore = model.evaluate(X_test, y_test, verbose=0)\nprint('Test loss:', score[0])\nprint('Test accuracy:', score[1])","metadata":{"execution":{"iopub.execute_input":"2023-04-23T21:42:41.922201Z","iopub.status.busy":"2023-04-23T21:42:41.921044Z","iopub.status.idle":"2023-04-23T22:26:50.732088Z","shell.execute_reply":"2023-04-23T22:26:50.730697Z"},"papermill":{"duration":2648.879167,"end_time":"2023-04-23T22:26:50.767298","exception":false,"start_time":"2023-04-23T21:42:41.888131","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# conclusion so far shows that using Long Short-Term Memory - using keras is a good model\n# with 0.83 accuracy (approx) however, it's important to note that accuracy alone is not always the best metric\n# and LSTM too a lot of time to train.\n","metadata":{"execution":{"iopub.execute_input":"2023-04-23T22:26:50.834314Z","iopub.status.busy":"2023-04-23T22:26:50.83379Z","iopub.status.idle":"2023-04-23T22:26:50.839085Z","shell.execute_reply":"2023-04-23T22:26:50.837787Z"},"papermill":{"duration":0.04143,"end_time":"2023-04-23T22:26:50.84149","exception":false,"start_time":"2023-04-23T22:26:50.80006","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]}]}